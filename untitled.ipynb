{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caae1b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15263 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15263/15263 [00:44<00:00, 342.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15263"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "model = 'vasflow'\n",
    "group = '10'\n",
    "epoch = '0169'\n",
    "\n",
    "# files = glob(f\"./log/2025_05_13-*-vaflow_sda_dit_noise_text_mel_10l_cc_first10/val/video/epoch_{epoch}*/audio_*_00.wav\")\n",
    "files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_06_14-23_*-vaflow_sda_dit_noise_text_mel_2_10l_cc_heinit_randdrop_svas/val/video/epoch_{epoch}*/audio_*_00.wav\")\n",
    "files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_06_22-14_*-vaflow_sda_dit_noise_text_mel_infer_va/predict/video/audio_*_00.wav\")\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_05_26-16*_dit_noise_text_clip_mel_infer/predict/video/audio_*_00.wav\")\n",
    "\n",
    "for audio_file in tqdm(files):\n",
    "    name = audio_file.split('/')[-1][6:-7]\n",
    "    target_file = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/{model}/{group}/{name}.wav\"\n",
    "    shutil.copy(audio_file, target_file)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcdcb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf7ade44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bd50575",
   "metadata": {},
   "source": [
    "# SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86398b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4713/4713 [00:00<00:00, 1026896.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(525, 3291, 200, 697)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import re\n",
    "\n",
    "model = 'vasflow'\n",
    "epoch = '0169'\n",
    "# files = glob(\"/home/chengxin/chengxin/vasflow/log/2025_05_07-13_*/predict/video/audio_*_00.wav\")\n",
    "files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_06_14-23_*-vaflow_sda_dit_noise_text_mel_2_10l_cc_heinit_randdrop_svas/val/video/epoch_{epoch}*/speech_*_00.wav\")\n",
    "files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_06_22-14_*-vaflow_sda_dit_noise_text_mel_infer_va/predict/video/speech_*_00.wav\")\n",
    "\n",
    "# files = glob(f\"/home/chengxin/chengxin/vasflow/log/2025_05_26-14_*_dit_noise_text_mel_infer/predict/video/speech_*_00.wav\")\n",
    "\n",
    "ljfiles = []\n",
    "gridfiles = []\n",
    "chemfiles = []\n",
    "lrsfiles = []\n",
    "for audio_file in tqdm(files):\n",
    "    name = audio_file.split('/')[-1][7:-7]\n",
    "    if name.startswith('LJ00'):\n",
    "        ljfiles.append(audio_file)\n",
    "    elif bool(re.match(r'^s(?:0[0-9]|[12][0-9]|3[0-5])', name)):\n",
    "        gridfiles.append(audio_file)\n",
    "    elif name.startswith('chem'):\n",
    "        chemfiles.append(audio_file)\n",
    "    else:\n",
    "        lrsfiles.append(audio_file)\n",
    "    # target_file = f\"/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/{model}/{group}/{name}.wav\"\n",
    "    # shutil.copy(audio_file, target_file)\n",
    "\n",
    "len(ljfiles), len(gridfiles), len(chemfiles), len(lrsfiles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d62350",
   "metadata": {},
   "source": [
    "# 1. wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33334a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/wav.scp\n"
     ]
    }
   ],
   "source": [
    "visualtts_dataset = 'Chem'\n",
    "meta_file_dir = f\"/home/chengxin/chengxin/Dataset_Sound/{visualtts_dataset}\"\n",
    "gen_file_paths = chemfiles\n",
    "output_scp_path = f\"{meta_file_dir}/results/{model}/wer/wav.scp\"\n",
    "\n",
    "\n",
    "with open(output_scp_path, \"w\") as scp_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "\n",
    "        name = f\"visual_tts_{file_id}_sample{sample_id}\"\n",
    "        gen_path = file_path\n",
    "        scp_file.write(f\"{name} {gen_path}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_scp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1caed",
   "metadata": {},
   "source": [
    "# 2. utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05a80f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/utt2spk\n"
     ]
    }
   ],
   "source": [
    "output_utt_path = f\"{meta_file_dir}/results/{model}/wer/utt2spk\"\n",
    "\n",
    "\n",
    "with open(output_utt_path, \"w\") as utt_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "        spk_id = '_'.join(file_id.split(\"_\")[:-1])\n",
    "\n",
    "\n",
    "        name = f\"{file_id}\"\n",
    "        gt_path = f\"{meta_file_dir}/speakers/{file_id}.wav\" # LJSpeech\n",
    "        gt_path = f\"{meta_file_dir}/speakers/{spk_id}/{file_id}.wav\"  # GRID LRS CHEM\n",
    "        utt_file.write(f\"{name} {gt_path}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_utt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccb0c3",
   "metadata": {},
   "source": [
    "# 3. Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c432253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/text\n"
     ]
    }
   ],
   "source": [
    "output_utt_path = f\"{meta_file_dir}/results/{model}/wer/text\"\n",
    "\n",
    "\n",
    "with open(output_utt_path, \"w\") as txt_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "        spk_id = '_'.join(file_id.split(\"_\")[:-1])\n",
    "        \n",
    "\n",
    "        name = f\"{file_id}\"\n",
    "        gt_transcript_path = f\"{meta_file_dir}/speakers/{file_id}.lab\" # LJSpeech\n",
    "        gt_transcript_path = f\"{meta_file_dir}/speakers/{spk_id}/{file_id}.lab\" # GRID LRS CHEM\n",
    "        with open(gt_transcript_path, \"r\") as lab_file:\n",
    "            gt_transcript = lab_file.read().strip()\n",
    "        txt_file.write(f\"{name} {gt_transcript}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_utt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5dd5c",
   "metadata": {},
   "source": [
    "# key_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06835483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written 3291 entries to /home/chengxin/chengxin/Dataset_Sound/GRID/results/vasflow/wer/key_file\n"
     ]
    }
   ],
   "source": [
    "output_utt_path = f\"{meta_file_dir}/results/{model}/wer/key_file\"\n",
    "\n",
    "\n",
    "with open(output_utt_path, \"w\") as key_file:\n",
    "    for file_path in gen_file_paths:\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "        sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "        \n",
    "        name = f\"visual_tts_{file_id}\"\n",
    "        key_file.write(f\"{name}\\n\")\n",
    "\n",
    "print(f\"Successfully written {len(gen_file_paths)} entries to {output_utt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48695190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3291/3291 [05:04<00:00, 10.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import subprocess\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "def replace_audio_in_video(video_path, audio_path, output_path):\n",
    "    \"\"\"\n",
    "    批量替换MP4文件的音频\n",
    "    video_folder: MP4文件所在文件夹\n",
    "    audio_folder: WAV文件所在文件夹\n",
    "    output_folder: 输出文件保存文件夹\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-y',\n",
    "            '-i', video_path,           # 输入视频文件\n",
    "            '-i', audio_path,          # 输入音频文件\n",
    "            '-c:v', 'copy',            # 直接复制视频流\n",
    "            '-c:a', 'aac',             # 编码音频为AAC\n",
    "            '-map', '0:v:0',           # 选择视频流的第0个视频轨道\n",
    "            '-map', '1:a:0',           # 选择音频流的第0个音频轨道\n",
    "            '-shortest',               # 以最短的流长度为准\n",
    "            output_path\n",
    "        ]\n",
    "            \n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        # print(f\"已处理: {output_path}\")\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     video = VideoFileClip(video_path)\n",
    "    #     audio = AudioFileClip(audio_path)\n",
    "        \n",
    "    #     # 如果音频时长比视频长，截断音频以匹配视频时长（类似 FFmpeg 的 -shortest）\n",
    "    #     if audio.duration > video.duration:\n",
    "    #         audio = audio.subclip(0, video.duration)\n",
    "    #     video_with_new_audio = video.set_audio(audio)\n",
    "        \n",
    "    #     video_with_new_audio.write_videofile(\n",
    "    #         output_path,\n",
    "    #         codec=\"libx264\",  # 视频编码\n",
    "    #         audio_codec=\"aac\",  # 音频编码\n",
    "    #         temp_audiofile=\"temp-audio.m4a\",\n",
    "    #         remove_temp=True,\n",
    "    #         verbose=False\n",
    "    #     )\n",
    "        \n",
    "    #     video.close()\n",
    "    #     audio.close()\n",
    "    #     video_with_new_audio.close()\n",
    "    #     # print(f\"已处理: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理失败: {output_path}, 错误: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "save_dir = f'/home/chengxin/chengxin/Dataset_Sound/{visualtts_dataset}/results/{model}/data'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for file_path in tqdm(gen_file_paths):\n",
    "    file_name = file_path.split(\"/\")[-1]\n",
    "    file_id = '_'.join(file_name.split(\"_\")[1:-1])\n",
    "    sample_id = int(file_name.split(\"_\")[-1][:-4])\n",
    "\n",
    "    name = f\"{file_id}_sample{sample_id}\"\n",
    "    shutil.copy(file_path, f\"{save_dir}/{name}.wav\")\n",
    "\n",
    "    if visualtts_dataset == 'Chem':\n",
    "        file_id = file_id[8:]\n",
    "        gt_video_path = f\"{meta_file_dir}/sentence_video_25fps/{file_id}.mp4\"  # Chem\n",
    "    elif visualtts_dataset == 'GRID':\n",
    "        spk = file_id.split(\"_\")[0]\n",
    "        gt_video_path = f\"{meta_file_dir}/videos_25fps_mp4/{spk}/{file_id}.mp4\"  # Chem\n",
    "    shutil.copy(gt_video_path, f\"{save_dir}/{name}.mp4\")\n",
    "    replace_audio_in_video(gt_video_path, f\"{save_dir}/{name}.wav\", f\"{save_dir}/{name}.mp4\")\n",
    "    # print(f\"{save_dir}/{name}.wav\", f\"{save_dir}/{name}.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81dc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f17f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "706ce5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/14286 [00:00<08:54, 26.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m waveform \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(waveform, (\u001b[38;5;241m0\u001b[39m, pad_length))\n\u001b[1;32m     17\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/chengxin/anaconda3/envs/vaflow/lib/python3.10/site-packages/torchaudio/_backend/utils.py:313\u001b[0m, in \u001b[0;36mget_save_func.<locals>.save\u001b[0;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, backend, compression)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save audio data to file.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mNote:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbits_per_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/chengxin/anaconda3/envs/vaflow/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py:316\u001b[0m, in \u001b[0;36mFFmpegBackend.save\u001b[0;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, compression)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compression, (torchaudio\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mCodecConfig, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))):\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFmpeg backend expects non-`None` value for argument `compression` to be of \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype `torchaudio.io.CodecConfig`, but received value of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(compression)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    315\u001b[0m     )\n\u001b[0;32m--> 316\u001b[0m \u001b[43msave_audio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbits_per_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/chengxin/anaconda3/envs/vaflow/lib/python3.10/site-packages/torchaudio/_backend/ffmpeg.py:256\u001b[0m, in \u001b[0;36msave_audio\u001b[0;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, compression)\u001b[0m\n\u001b[1;32m    247\u001b[0m s \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mStreamWriter(uri, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mmuxer, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size)\n\u001b[1;32m    248\u001b[0m s\u001b[38;5;241m.\u001b[39madd_audio_stream(\n\u001b[1;32m    249\u001b[0m     sample_rate,\n\u001b[1;32m    250\u001b[0m     num_channels\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m     codec_config\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    255\u001b[0m )\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m s\u001b[38;5;241m.\u001b[39mopen():\n\u001b[1;32m    257\u001b[0m     s\u001b[38;5;241m.\u001b[39mwrite_audio_chunk(\u001b[38;5;241m0\u001b[39m, src)\n",
      "File \u001b[0;32m~/chengxin/anaconda3/envs/vaflow/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py:502\u001b[0m, in \u001b[0;36mStreamingMediaEncoder.__exit__\u001b[0;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Context manager so that the destination is closed and data are flushed automatically.\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/chengxin/anaconda3/envs/vaflow/lib/python3.10/site-packages/torio/io/_streaming_media_encoder.py:451\u001b[0m, in \u001b[0;36mStreamingMediaEncoder.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Close the output\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m:py:class:`StreamingMediaEncoder` is also a context manager and therefore supports the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03mSee :py:meth:`StreamingMediaEncoder.open` for more detail.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_open:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_open \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchaudio,os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob,tqdm\n",
    "\n",
    "target_duration = 10  # seconds\n",
    "target_dir = '/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/vaura/10'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "gen_file_paths = os.listdir('/home/chengxin/chengxin/V-AURA/demo_output/generated_samples_25-05-21T23-06-07')\n",
    "for file_path in tqdm.tqdm(gen_file_paths):\n",
    "    waveform, sample_rate = torchaudio.load(f'/home/chengxin/chengxin/V-AURA/demo_output/generated_samples_25-05-21T23-06-07/{file_path}')\n",
    "    current_duration = waveform.shape[1] / sample_rate\n",
    "\n",
    "    waveform = torch.cat([waveform] * 3, dim=1)\n",
    "    pad_length = int(target_duration * sample_rate) - waveform.shape[1]\n",
    "    waveform = nn.functional.pad(waveform, (0, pad_length))\n",
    "    save_path = f\"{target_dir}/{file_path}\"\n",
    "    torchaudio.save(save_path, waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3b49902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14277/14277 [00:00<00:00, 24087.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "\n",
    "audio_files = os.listdir('/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/vaura/10')\n",
    "from_files = os.listdir('/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/vasflow/10')\n",
    "c = 0\n",
    "for file in tqdm.tqdm(from_files):\n",
    "    if file not in audio_files:\n",
    "        os.remove(f'/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/vasflow/10/{file}')\n",
    "        print(f\"Removed: {file}\")\n",
    "        c += 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2a18bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15272/15272 [07:16<00:00, 34.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import torchaudio,os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob,tqdm\n",
    "\n",
    "target_duration = 10  # seconds\n",
    "gen_file_paths = glob.glob('/home/chengxin/chengxin/Dataset_Sound/VGGSound/generated_audios/mmaudio/10/*.wav')\n",
    "for file_path in tqdm.tqdm(gen_file_paths):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    current_duration = waveform.shape[1] / sample_rate\n",
    "\n",
    "    # waveform = torch.cat([waveform] * 3, dim=1)\n",
    "    pad_length = int(target_duration * sample_rate) - waveform.shape[1]\n",
    "    waveform = nn.functional.pad(waveform, (0, pad_length))\n",
    "    torchaudio.save(file_path, waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2d87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de225a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3292/3292 [00:00<00:00, 4177.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "\n",
    "files = glob(\"/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/data/*.wav\")\n",
    "for file in tqdm(files):\n",
    "    name = file.split(\"/\")[-1][:-4]\n",
    "    shutil.move(file,f\"/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/data/{name}_sample0.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "865cc59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3291/3291 [00:00<00:00, 3672.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/data/s08_brifza_sample0.wav')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "wav_scp_path = f\"/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/wer/wav_ori.scp\"\n",
    "\n",
    "with open(wav_scp_path, \"r\") as f:\n",
    "    wav_scp_lines = f.readlines()\n",
    "\n",
    "lines = []\n",
    "c = 0\n",
    "for line in tqdm(wav_scp_lines):  # 只显示前5行作为示例\n",
    "    line = line.strip().split(\" \")\n",
    "    # path = line[1].replace(\"gt_test\", \"gt_vocoder\")\n",
    "    path = f\"/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/data/{line[1].split('/')[-1][7:-7]}_sample0.wav\"\n",
    "    # path = f\"/home/chengxin/chengxin/Dataset_Sound/GRID/results/style3/data/{line[1].split('/')[-1]}\"\n",
    "    # path = line[1]\n",
    "    if not os.path.exists(path):\n",
    "        c += 1\n",
    "        continue\n",
    "    lines.append([line[0], path])\n",
    "    \n",
    "with open('/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/wer/wav.scp', \"w\") as f:\n",
    "    for name, path in lines:\n",
    "        f.write(f\"{name} {path}\\n\")\n",
    "\n",
    "c, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "250c3431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3286"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(\"/home/chengxin/chengxin/Dataset_Sound/GRID/results/style3/data\")\n",
    "files = [i[:-12] for i in files]\n",
    "\n",
    "all_keys = []\n",
    "all_keys = all_keys + files\n",
    "all_keys = all_keys + [f\"visual_tts_{i}\" for i in files]\n",
    "all_keys = all_keys + [f\"visual_tts_{i}_sample0\" for i in files]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5733890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "wav_scp_path = f\"/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/wer/wav.scp\"\n",
    "\n",
    "with open(wav_scp_path, \"r\") as f:\n",
    "    wav_scp_lines = f.readlines()\n",
    "\n",
    "\n",
    "lines = []\n",
    "c = 0\n",
    "for line in tqdm(wav_scp_lines):  # 只显示前5行作为示例\n",
    "    # line = line.strip().split(\" \")\n",
    "    # line = \" \".join(line)\n",
    "    line = line.strip()\n",
    "    line = line.replace(\"style3\", \"gt_test\")\n",
    "    # if line[0] not in all_keys:\n",
    "    #     c += 1\n",
    "    #     continue\n",
    "    lines.append(line)\n",
    "\n",
    "lines.sort()\n",
    "with open('/home/chengxin/chengxin/Dataset_Sound/GRID/results/gt_test/wer/wav.scp', \"w\") as f:\n",
    "    for line in lines:\n",
    "        f.write(f\"{line}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "len(lines), lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bf9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df181f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced989a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d360e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:06<00:00, 518.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def convert_name(name):\n",
    "    match = re.match(r's(\\d+)-(.*)', name)\n",
    "    if match:\n",
    "        num = match.group(1).zfill(2)\n",
    "        rest = match.group(2)\n",
    "        return f's{num}_{rest}'\n",
    "    return name\n",
    "\n",
    "# converted = convert_name(file)\n",
    "# print(converted)\n",
    "\n",
    "\n",
    "source_dir = '/home/chengxin/chengxin/Dataset_Sound/GRID/results/HPMDubbing_randomref/data_ori/wavfiles'\n",
    "target_dir = '/home/chengxin/chengxin/Dataset_Sound/GRID/results/HPMDubbing_randomref/data'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "for file in tqdm(os.listdir(source_dir)):\n",
    "    converted_file = file.split(\".\")[0]\n",
    "    converted_file = converted_file.split(\"_\")[-1]\n",
    "    converted_file = convert_name(converted_file)\n",
    "    # print(file, converted_file)\n",
    "    # break\n",
    "    shutil.copy(f\"{source_dir}/{file}\", f\"{target_dir}/{converted_file}_sample0.wav\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08156c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11c146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763e42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_audio_in_video(video_path, audio_path, output_path):\n",
    "    \"\"\"\n",
    "    批量替换MP4文件的音频\n",
    "    video_folder: MP4文件所在文件夹\n",
    "    audio_folder: WAV文件所在文件夹\n",
    "    output_folder: 输出文件保存文件夹\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-y',\n",
    "            '-i', video_path,           # 输入视频文件\n",
    "            '-i', audio_path,          # 输入音频文件\n",
    "            '-c:v', 'copy',            # 直接复制视频流\n",
    "            '-c:a', 'aac',             # 编码音频为AAC\n",
    "            '-map', '0:v:0',           # 选择视频流的第0个视频轨道\n",
    "            '-map', '1:a:0',           # 选择音频流的第0个音频轨道\n",
    "            '-shortest',               # 以最短的流长度为准\n",
    "            output_path\n",
    "        ]\n",
    "            \n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        # print(f\"已处理: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理失败: {output_path}, 错误: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f444e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:28<00:00,  6.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob, os, shutil, subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "visualtts_dataset = 'Chem'\n",
    "meta_file_dir = f\"/home/chengxin/chengxin/Dataset_Sound/{visualtts_dataset}\"\n",
    "\n",
    "save_dir = f'/home/chengxin/chengxin/Dataset_Sound/Chem/results/emodubber/data'\n",
    "gen_file_paths = glob.glob('/home/chengxin/chengxin/EmoDubber/generated_resulst/Chem/Setting2_Chem_outputWav_Step_1399/*.wav')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for file_path in tqdm(gen_file_paths):\n",
    "    file_name = file_path.split(\"/\")[-1]\n",
    "    file_id = file_name.split(\".\")[0]\n",
    "    sample_id = 0\n",
    "\n",
    "    name = f\"chem_00_{file_id}_sample{sample_id}\"\n",
    "    shutil.copy(file_path, f\"{save_dir}/{name}.wav\")\n",
    "\n",
    "    # elif visualtts_dataset == 'GRID':\n",
    "    #     spk = file_id.split(\"_\")[0]\n",
    "    #     gt_video_path = f\"{meta_file_dir}/videos_25fps_mp4/{spk}/{file_id}.mp4\"  # Chem\n",
    "    gt_video_path = f\"{meta_file_dir}/sentence_video_25fps/{file_id}.mp4\"  # Chem\n",
    "    # print(gt_video_path, f\"{save_dir}/{name}.mp4\")\n",
    "    shutil.copy(gt_video_path, f\"{save_dir}/{name}.mp4\")\n",
    "    replace_audio_in_video(gt_video_path, f\"{save_dir}/{name}.wav\", f\"{save_dir}/{name}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8389e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
